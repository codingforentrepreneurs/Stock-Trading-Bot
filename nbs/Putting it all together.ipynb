{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e85ed483-d2ef-4920-a1b5-51dd0eddf4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import setup\n",
    "setup.init_django()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b9ca555-32fb-4f46-a606-48e409b235f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from market import services as market_services\n",
    "from market import tasks as market_tasks\n",
    "from market.models import Company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17a821e5-1584-47f7-b53b-c2d204deabfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from decouple import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d27cf2-6c7c-4dfa-9425-6da85d9a0e32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b007fdc-9a97-4d82-b386-e1e885704073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticker = \"AAPL\"\n",
    "name = \"Apple\"\n",
    "company, _ = Company.objects.get_or_create(name=name, ticker=ticker)\n",
    "company.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5248e7f5-eb8b-4c41-bd1a-6b0998ec7267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Historical sync days ago 30\n",
      "dataset length 4197\n",
      "Doing chunk 0\n",
      "finished chunk 0\n",
      "Doing chunk 1000\n",
      "finished chunk 1000\n",
      "Doing chunk 2000\n",
      "finished chunk 2000\n",
      "Doing chunk 3000\n",
      "finished chunk 3000\n",
      "Doing chunk 4000\n",
      "finished chunk 4000\n",
      "30 done\n",
      "\n",
      "Historical sync days ago 60\n",
      "dataset length 8043\n",
      "Doing chunk 0\n",
      "finished chunk 0\n",
      "Doing chunk 1000\n",
      "finished chunk 1000\n",
      "Doing chunk 2000\n",
      "finished chunk 2000\n",
      "Doing chunk 3000\n",
      "finished chunk 3000\n",
      "Doing chunk 4000\n",
      "finished chunk 4000\n",
      "Doing chunk 5000\n",
      "finished chunk 5000\n",
      "Doing chunk 6000\n",
      "finished chunk 6000\n",
      "Doing chunk 7000\n",
      "finished chunk 7000\n",
      "Doing chunk 8000\n",
      "finished chunk 8000\n",
      "60 done\n",
      "\n",
      "Historical sync days ago 90\n",
      "dataset length 11692\n",
      "Doing chunk 0\n",
      "finished chunk 0\n",
      "Doing chunk 1000\n",
      "finished chunk 1000\n",
      "Doing chunk 2000\n",
      "finished chunk 2000\n",
      "Doing chunk 3000\n",
      "finished chunk 3000\n",
      "Doing chunk 4000\n",
      "finished chunk 4000\n",
      "Doing chunk 5000\n",
      "finished chunk 5000\n",
      "Doing chunk 6000\n",
      "finished chunk 6000\n",
      "Doing chunk 7000\n",
      "finished chunk 7000\n",
      "Doing chunk 8000\n",
      "finished chunk 8000\n",
      "Doing chunk 9000\n",
      "finished chunk 9000\n",
      "Doing chunk 10000\n",
      "finished chunk 10000\n",
      "Doing chunk 11000\n",
      "finished chunk 11000\n",
      "90 done\n",
      "\n",
      "Historical sync days ago 120\n",
      "dataset length 12422\n",
      "Doing chunk 0\n",
      "finished chunk 0\n",
      "Doing chunk 1000\n",
      "finished chunk 1000\n",
      "Doing chunk 2000\n",
      "finished chunk 2000\n",
      "Doing chunk 3000\n",
      "finished chunk 3000\n",
      "Doing chunk 4000\n",
      "finished chunk 4000\n",
      "Doing chunk 5000\n",
      "finished chunk 5000\n",
      "Doing chunk 6000\n",
      "finished chunk 6000\n",
      "Doing chunk 7000\n",
      "finished chunk 7000\n",
      "Doing chunk 8000\n",
      "finished chunk 8000\n",
      "Doing chunk 9000\n",
      "finished chunk 9000\n",
      "Doing chunk 10000\n",
      "finished chunk 10000\n",
      "Doing chunk 11000\n",
      "finished chunk 11000\n",
      "Doing chunk 12000\n",
      "finished chunk 12000\n",
      "120 done\n",
      "\n",
      "Historical sync days ago 150\n",
      "dataset length 12264\n",
      "Doing chunk 0\n",
      "finished chunk 0\n",
      "Doing chunk 1000\n",
      "finished chunk 1000\n",
      "Doing chunk 2000\n",
      "finished chunk 2000\n",
      "Doing chunk 3000\n",
      "finished chunk 3000\n",
      "Doing chunk 4000\n",
      "finished chunk 4000\n",
      "Doing chunk 5000\n",
      "finished chunk 5000\n",
      "Doing chunk 6000\n",
      "finished chunk 6000\n",
      "Doing chunk 7000\n",
      "finished chunk 7000\n",
      "Doing chunk 8000\n",
      "finished chunk 8000\n",
      "Doing chunk 9000\n",
      "finished chunk 9000\n",
      "Doing chunk 10000\n",
      "finished chunk 10000\n",
      "Doing chunk 11000\n",
      "finished chunk 11000\n",
      "Doing chunk 12000\n",
      "finished chunk 12000\n",
      "150 done\n",
      "\n",
      "Historical sync days ago 180\n",
      "dataset length 12131\n",
      "Doing chunk 0\n",
      "finished chunk 0\n",
      "Doing chunk 1000\n",
      "finished chunk 1000\n",
      "Doing chunk 2000\n",
      "finished chunk 2000\n",
      "Doing chunk 3000\n",
      "finished chunk 3000\n",
      "Doing chunk 4000\n",
      "finished chunk 4000\n",
      "Doing chunk 5000\n",
      "finished chunk 5000\n",
      "Doing chunk 6000\n",
      "finished chunk 6000\n",
      "Doing chunk 7000\n",
      "finished chunk 7000\n",
      "Doing chunk 8000\n",
      "finished chunk 8000\n",
      "Doing chunk 9000\n",
      "finished chunk 9000\n",
      "Doing chunk 10000\n",
      "finished chunk 10000\n",
      "Doing chunk 11000\n",
      "finished chunk 11000\n",
      "Doing chunk 12000\n",
      "finished chunk 12000\n",
      "180 done\n",
      "\n",
      "Historical sync days ago 210\n",
      "dataset length 12157\n",
      "Doing chunk 0\n",
      "finished chunk 0\n",
      "Doing chunk 1000\n",
      "finished chunk 1000\n",
      "Doing chunk 2000\n",
      "finished chunk 2000\n",
      "Doing chunk 3000\n",
      "finished chunk 3000\n",
      "Doing chunk 4000\n",
      "finished chunk 4000\n",
      "Doing chunk 5000\n",
      "finished chunk 5000\n",
      "Doing chunk 6000\n",
      "finished chunk 6000\n",
      "Doing chunk 7000\n",
      "finished chunk 7000\n",
      "Doing chunk 8000\n",
      "finished chunk 8000\n",
      "Doing chunk 9000\n",
      "finished chunk 9000\n",
      "Doing chunk 10000\n",
      "finished chunk 10000\n",
      "Doing chunk 11000\n",
      "finished chunk 11000\n",
      "Doing chunk 12000\n",
      "finished chunk 12000\n",
      "210 done\n",
      "\n",
      "Historical sync days ago 240\n",
      "dataset length 12176\n",
      "Doing chunk 0\n",
      "finished chunk 0\n",
      "Doing chunk 1000\n",
      "finished chunk 1000\n",
      "Doing chunk 2000\n",
      "finished chunk 2000\n",
      "Doing chunk 3000\n",
      "finished chunk 3000\n",
      "Doing chunk 4000\n",
      "finished chunk 4000\n",
      "Doing chunk 5000\n",
      "finished chunk 5000\n",
      "Doing chunk 6000\n",
      "finished chunk 6000\n",
      "Doing chunk 7000\n",
      "finished chunk 7000\n",
      "Doing chunk 8000\n",
      "finished chunk 8000\n",
      "Doing chunk 9000\n",
      "finished chunk 9000\n",
      "Doing chunk 10000\n",
      "finished chunk 10000\n",
      "Doing chunk 11000\n",
      "finished chunk 11000\n",
      "Doing chunk 12000\n",
      "finished chunk 12000\n",
      "240 done\n",
      "\n",
      "Historical sync days ago 270\n",
      "dataset length 12176\n",
      "Doing chunk 0\n",
      "finished chunk 0\n",
      "Doing chunk 1000\n",
      "finished chunk 1000\n",
      "Doing chunk 2000\n",
      "finished chunk 2000\n",
      "Doing chunk 3000\n",
      "finished chunk 3000\n",
      "Doing chunk 4000\n",
      "finished chunk 4000\n",
      "Doing chunk 5000\n",
      "finished chunk 5000\n",
      "Doing chunk 6000\n",
      "finished chunk 6000\n",
      "Doing chunk 7000\n",
      "finished chunk 7000\n",
      "Doing chunk 8000\n",
      "finished chunk 8000\n",
      "Doing chunk 9000\n",
      "finished chunk 9000\n",
      "Doing chunk 10000\n",
      "finished chunk 10000\n",
      "Doing chunk 11000\n",
      "finished chunk 11000\n",
      "Doing chunk 12000\n",
      "finished chunk 12000\n",
      "270 done\n",
      "\n",
      "Historical sync days ago 300\n",
      "dataset length 12141\n",
      "Doing chunk 0\n",
      "finished chunk 0\n",
      "Doing chunk 1000\n",
      "finished chunk 1000\n",
      "Doing chunk 2000\n",
      "finished chunk 2000\n",
      "Doing chunk 3000\n",
      "finished chunk 3000\n",
      "Doing chunk 4000\n",
      "finished chunk 4000\n",
      "Doing chunk 5000\n",
      "finished chunk 5000\n",
      "Doing chunk 6000\n",
      "finished chunk 6000\n",
      "Doing chunk 7000\n",
      "finished chunk 7000\n",
      "Doing chunk 8000\n",
      "finished chunk 8000\n",
      "Doing chunk 9000\n",
      "finished chunk 9000\n",
      "Doing chunk 10000\n",
      "finished chunk 10000\n",
      "Doing chunk 11000\n",
      "finished chunk 11000\n",
      "Doing chunk 12000\n",
      "finished chunk 12000\n",
      "300 done\n",
      "\n",
      "Historical sync days ago 330\n",
      "dataset length 12171\n",
      "Doing chunk 0\n",
      "finished chunk 0\n",
      "Doing chunk 1000\n",
      "finished chunk 1000\n",
      "Doing chunk 2000\n",
      "finished chunk 2000\n",
      "Doing chunk 3000\n",
      "finished chunk 3000\n",
      "Doing chunk 4000\n",
      "finished chunk 4000\n",
      "Doing chunk 5000\n",
      "finished chunk 5000\n",
      "Doing chunk 6000\n",
      "finished chunk 6000\n",
      "Doing chunk 7000\n",
      "finished chunk 7000\n",
      "Doing chunk 8000\n",
      "finished chunk 8000\n",
      "Doing chunk 9000\n",
      "finished chunk 9000\n",
      "Doing chunk 10000\n",
      "finished chunk 10000\n",
      "Doing chunk 11000\n",
      "finished chunk 11000\n",
      "Doing chunk 12000\n",
      "finished chunk 12000\n",
      "330 done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "market_tasks.sync_historical_stock_data(years_ago=1, company_ids=[company.id], use_celery=False, verbose=True)\n",
    "\n",
    "# use celery / async\n",
    "# market_tasks.sync_historical_stock_data.delay(years_ago=5, company_ids=[company.id], use_celery=True, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd8d0220-ec15-4a25-9d51-764c41ae1f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': -1,\n",
       " 'ticker': 'AAPL',\n",
       " 'indicators': {'ma_5': 225.598,\n",
       "  'ma_20': 227.6609,\n",
       "  'current_price': 227.75,\n",
       "  'conservative_target': 235.5237,\n",
       "  'aggressive_target': 240.3263,\n",
       "  'average_price': 226.4995,\n",
       "  'avg_volume': 4692.446153846154,\n",
       "  'latest_volume': 341,\n",
       "  'volume_change_percent': -92.7330013212725,\n",
       "  'rsi': 48.8471,\n",
       "  'avg_gain': 0.9153,\n",
       "  'avg_loss': 0.9585,\n",
       "  'period': 14,\n",
       "  'days': 90}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = market_services.get_stock_indicators(ticker=ticker, days=90)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e5ec9bd-786c-405c-abe3-157889edefe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"score\": -1, \"ticker\": \"AAPL\", \"indicators\": {\"ma_5\": 225.598, \"ma_20\": 227.6609, \"current_price\": 227.75, \"conservative_target\": 233.4647, \"aggressive_target\": 236.9953, \"average_price\": 228.572, \"avg_volume\": 4489.916666666667, \"latest_volume\": 341, \"volume_change_percent\": -92.4052042539765, \"rsi\": 42.9317, \"avg_gain\": 0.8474, \"avg_loss\": 1.1265, \"period\": 14, \"days\": 30}}'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_as_json = json.dumps(results)\n",
    "results_as_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f7cb784-4c04-4c3c-a37e-75b54be43388",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY=config(\"OPENAI_API_KEY\", default=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "879c180e-8fbb-47ca-a7e6-cd6e56c0639c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert OPENAI_API_KEY is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "604bbae2-876e-4e94-8db4-9f070d2e6082",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c6817f4-6676-4e2d-af52-4492e11bdc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an expert an analyzing stocks and respond in JSON data\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Considering these results {results_as_json}, provide a recommendation\"}\n",
    "    ],\n",
    "    response_format={\n",
    "        \"type\": \"json_schema\",\n",
    "        \"json_schema\": {\n",
    "            \"name\": \"recommendation\",\n",
    "            \"schema\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"buy\": {\n",
    "                        \"description\": \"Recommend to buy stock\",\n",
    "                        \"type\": \"boolean\"\n",
    "                    },\n",
    "                    \"sell\": {\n",
    "                        \"description\": \"Recommend to sell stock\",\n",
    "                        \"type\": \"boolean\"\n",
    "                    },\n",
    "                    \"hold\": {\n",
    "                        \"description\": \"Recommend to hold stock\",\n",
    "                        \"type\": \"boolean\"\n",
    "                    },\n",
    "                    \"explanation\": {\n",
    "                        \"description\": \"Explanation of reasoning in 1 or 2 sentences\",\n",
    "                        \"type\": \"string\"\n",
    "                    },\n",
    "                    \"additionalProperties\": False\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0b30373-f882-41a7-a569-f5f543cfe7b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'buy': False,\n",
       " 'sell': True,\n",
       " 'hold': False,\n",
       " 'explanation': 'Given the negative score and significant drop in volume along with an RSI of 42, which indicates potential weakness, it is advisable to sell the stock.'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = json.loads(response.choices[0].message.content)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b14531ce-5dfc-4620-96c7-bcab3d0dec45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.get('hold') is True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c65d0c6-3fd2-4315-850d-cdc1c6b8b835",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
